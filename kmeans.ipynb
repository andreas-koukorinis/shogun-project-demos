{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Kmeans Algorithms on NBA Player Play Type Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ting Pan, github ID: [tingpan](https://github.com/tingpan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous [project](http://dota666.com/basketball/), we just did a very simple statistics and visualization, which is not insightful and interesting. I think we could apply some unsupervised clustering analysis (such as K-Means Clustering) with Shogun API on the dataset to classify the player into different type. \n",
    "\n",
    "This notebook shows clustering NBA Play Type Stats with KMeans in Shogun. Since I do not know how many types of players are there, I will use K-means and Elbow Method to find out the most suitable value of k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I will load the dataset. `play_freq.data` contains NBA Season 2015-16 play type stats from [stats.nba.com](http://stats.nba.com/). This comma-separated file contains 11 columns, which first column is player names and last 10 are frequence of 10 play types(Transition, Isolation, Pick & Roll, Pick & Roll: Roll Man, Post-Up, Spot-Up, Hand-Off, Cut, Off Screen and Rebound). I will load data from file and build features for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "def load_data():\n",
    "    f = open('./play_freq.data')\n",
    "    features = []\n",
    "    names = []\n",
    "    for line in f:\n",
    "        words = line.rstrip().split(',')\n",
    "        # Store player names\n",
    "        names.append(words[0])\n",
    "        # Store features of each player\n",
    "        features.append([float(i) for i in words[1:]])\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    return (array(features).T, names)\n",
    "data, names = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data object contains play types frequency of nearly 400 players. After obtained features of dataset, I will define the KMeans training method with Shogun Python API. I will use KMeans++ to make sure final centers mostly correspond to the global minima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modshogun import *\n",
    "def train_kmeans(k, data):\n",
    "    train_features = RealFeatures(data)\n",
    "    # calculate euclidean distance of features\n",
    "    distance = EuclideanDistance(train_features, train_features)\n",
    "\n",
    "    # initialize KMeans++ object\n",
    "    kmeans = KMeans(k, distance, True)\n",
    "\n",
    "    # training kmeans\n",
    "    kmeans.train(train_features)\n",
    "\n",
    "    # labels for data points\n",
    "    result = kmeans.apply()\n",
    "    centers = kmeans.get_cluster_centers()\n",
    "    radiuses = kmeans.get_radiuses()\n",
    "    return result, centers, radiuses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I can train the dataset with specifying the number of clusters(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying the number of clusters(k)\n",
    "# However, the actual amount of types is unknown\n",
    "k = 8\n",
    "result, centers, radiuses = train_kmeans(k, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I don't know the total amount of types, I will use Elbow Method to find out the most suitable value of k (i.e. type amount). I will run k-means clustering on the dataset with an increasing k. For each k, I will calculate the loss. The best k would be the k with a small loss and the trend of loss decreasing is diminishing.\n",
    "\n",
    "I will run KMeans clustering on the dataset for a range of values of k, and for each value of k calculate the sum of radiuses. To ensure the final centers mostly correspond to the global minima, for each value of k I will train the dataset 10 times(As this is a demo, to increase speed of the notebook, I will only train 10 times.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = []\n",
    "xs = []\n",
    "for k in range(5, 50):\n",
    "    xs.append(k)\n",
    "    _ys = []\n",
    "    for i in range(1, 11):\n",
    "        result, centers, radiuses = train_kmeans(k, data)\n",
    "        _ys.append(sum(radiuses)/k)\n",
    "    ys.append(sum(_ys)/10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, I will plot a line chart of the average radiuses for each value of k; If the line chart looks like an arm, then the \"elbow\" on the arm is the value of k that is the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(xs,ys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in figure, the best value of k is 25. After finding the best value of k, I will train the dataset to get all players types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 25\n",
    "result, centers, radiuses = train_kmeans(k, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}